{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Degree-of-Freedom System\n",
    "\n",
    "### Known\n",
    "- $ \\left[ M \\right] $ \n",
    "- $ a_0,\\ a_1 $\n",
    "- $ \\left[ C \\right] = a_0 \\left[ M \\right] + a_1 \\left[ K \\right] $\n",
    "- $ K_{ij} \\geq 0\\ \\forall (i, j) \\in \\mathbb{N} \\times \\mathbb{N} $\n",
    "- $ \\left[ K \\right] $ is sparse\n",
    "- $ \\left[ K \\right] = \\sum_{i=1}^4 \\left[ \\mathbb{K}_\\text{basis} \\right]_i \\cdot E_i $\n",
    "\n",
    "### Unknown\n",
    "- $ \\mathbb{E} = \\bigcup_{i=1}^4 E_i $\n",
    "- $ \\alpha_\\pi $\n",
    "\n",
    "### Constraints\n",
    "- $ \\mathcal{J}_\\mathcal{D} = \\frac{1}{2} \\sum_{i=1,2} \\left( \\hat{u}_i - u_i \\right)^2 $ (data loss)\n",
    "- $ E_{ij} \\geq 0\\ \\forall (i, j) \\in \\mathbb{N} \\times \\mathbb{N} $ (hard constraint)\n",
    "- $ \\mathcal{J}_\\pi = \\alpha_\\pi \\mathcal{L}_2\\left( \\left[ M \\right]\\left[ \\ddot{u} \\right] + \\left[ C \\right]\\left[ \\dot{u} \\right] + \\left[ K \\right]\\left[ u \\right] - \\left[ f(t) \\right] \\right) $\n",
    "- $ \\mathcal{J}_\\mathcal{S} = \\mathcal{L}_1\\left( \\left[ K \\right] \\right) $ (sparsity enforcement, not used here because the 4DOF K-matrix is not actually sparse)\n",
    "\n",
    "### Definitions\n",
    "$\\mathcal{L}_1$: Taxicab norm\\\n",
    "$\\mathcal{L}_2$: Euclidiean norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing libraries...\")\n",
    "## Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import deepxde as dde\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.integrate import odeint\n",
    "print(\"Done.\")\n",
    "\n",
    "## Set hyperparameters\n",
    "np.random.seed(123)\n",
    "N_DEGREES_OF_FREEDOM = 4\n",
    "N_COLLOC_POINTS = 50\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining training data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining training data...\")\n",
    "## Define Known Values\n",
    "omega1 = 2 * np.pi * 1.5 #1.5 hz first mode\n",
    "omega2 = 2 * np.pi * 14\n",
    "damp1 = 0.01\n",
    "damp2 = 0.02\n",
    "a0 = ( 2 * damp1 * omega1 * (omega2**2) - 2 * damp2 * omega2 * (omega1**2) ) / ( (omega2**2) -(omega1**2) )\n",
    "a1 = ( 2 * damp2 * omega2 - 2 * damp1 * omega1 ) / ( (omega2**2) -(omega1**2) )\n",
    "\n",
    "m = np.diag( np.ones(N_DEGREES_OF_FREEDOM) )\n",
    "e = np.random.rand(N_DEGREES_OF_FREEDOM)\n",
    "\n",
    "first_diag = int( np.floor(N_DEGREES_OF_FREEDOM*3/4) )\n",
    "k_basis = np.transpose(np.array([\n",
    "    np.diag(np.random.rand(N_DEGREES_OF_FREEDOM))\n",
    "    +\n",
    "    np.diag(np.random.rand(first_diag), k=N_DEGREES_OF_FREEDOM-first_diag) * 0.6\n",
    "    +\n",
    "    np.diag(np.random.rand(first_diag), k=-(N_DEGREES_OF_FREEDOM-first_diag)) * 0.6\n",
    "    for _ in range(N_DEGREES_OF_FREEDOM)\n",
    "]), axes=(1, 0, 2))\n",
    "\n",
    "k = np.dot(e, k_basis)\n",
    "c = a0 * m + a1 * k\n",
    "\n",
    "force_index = 1\n",
    "def np_force(t):\n",
    "    force_mask = np.zeros( N_DEGREES_OF_FREEDOM ).reshape(-1, 1)\n",
    "    force_mask[force_index] = 1\n",
    "    return np.exp(-(t-np.pi)**2) * np.sin(2*np.pi*t) * force_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solve ODE\n",
    "def ode(u, t):\n",
    "    y    = u[ 0 : N_DEGREES_OF_FREEDOM ].reshape(-1, 1)\n",
    "    y_t  = u[ N_DEGREES_OF_FREEDOM : ].reshape(-1, 1)\n",
    "            \n",
    "    y_tt = np.linalg.inv(m) @ (\n",
    "        np_force(t)\n",
    "        -\n",
    "        c @ y_t\n",
    "        -\n",
    "        k @ y\n",
    "    )\n",
    "    return np.array( list( y_t.squeeze() ) + list(y_tt.squeeze()) )\n",
    "\n",
    "u0 = np.zeros( N_DEGREES_OF_FREEDOM * 2 )\n",
    "t  = np.linspace( 0, 4 * np.pi, 150 )\n",
    "\n",
    "sol = odeint(ode, u0, t)\n",
    "u   = sol[:, :N_DEGREES_OF_FREEDOM]\n",
    "u_t = sol[:, N_DEGREES_OF_FREEDOM:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Plotting...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## Screen out training data\n",
    "time_indices   = np.arange( 0, len(t), len(t) // N_COLLOC_POINTS )\n",
    "sensor_indices = [1, 3]\n",
    "\n",
    "tdata = t[time_indices]\n",
    "udata = u[time_indices]  # this data includes all dimensions, not just the sensor dimensions\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Plotting...\")\n",
    "## Plot\n",
    "fig, ax = plt.subplots(N_DEGREES_OF_FREEDOM, 1, sharex=True)\n",
    "plt.suptitle(\"Solution and Data\")\n",
    "for dim in range(N_DEGREES_OF_FREEDOM):\n",
    "    ax[dim].plot(t, u[:, dim], label=\"Solution\")\n",
    "    if dim in sensor_indices:\n",
    "        ax[dim].plot(tdata, udata[:, dim], label=\"Data\", linestyle=\"None\", marker=\".\")\n",
    "    ax[dim].set_xlabel(r\"$t$\")\n",
    "    ax[dim].set_ylabel(r\"$u_{}(t)$\".format(dim + 1))\n",
    "    if dim == 0:\n",
    "        ax[dim].legend(loc=\"upper right\", ncol=2)\n",
    "plt.savefig(\"plots/training_data.png\")\n",
    "plt.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up DeepXDE model...\n",
      "Compiling model...\n",
      "'compile' took 0.000231 s\n",
      "\n",
      "Done.\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric\n",
      "0         [1.29e-01, 4.30e-04, 7.99e-05]    [1.12e-01, 4.30e-04, 7.99e-05]    []  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m checkpoint\u001b[39m.\u001b[39mon_epoch_begin \u001b[39m=\u001b[39m plot\n\u001b[0;32m     98\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m losshistory, train_state \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(iterations\u001b[39m=\u001b[39;49m\u001b[39m2_000_000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[variable, checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     23\u001b[0m     te \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m took \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m s\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, te \u001b[39m-\u001b[39m ts))\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:624\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[39mif\u001b[39;00m iterations \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo iterations for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_name))\n\u001b[1;32m--> 624\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_sgd(iterations, display_every)\n\u001b[0;32m    625\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mon_train_end()\n\u001b[0;32m    627\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:641\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[1;34m(self, iterations, display_every)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mon_batch_begin()\n\u001b[0;32m    638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_state\u001b[39m.\u001b[39mset_data_train(\n\u001b[0;32m    639\u001b[0m     \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtrain_next_batch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[0;32m    640\u001b[0m )\n\u001b[1;32m--> 641\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step(\n\u001b[0;32m    642\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_state\u001b[39m.\u001b[39;49mX_train,\n\u001b[0;32m    643\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_state\u001b[39m.\u001b[39;49my_train,\n\u001b[0;32m    644\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_state\u001b[39m.\u001b[39;49mtrain_aux_vars,\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    647\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_state\u001b[39m.\u001b[39mepoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_state\u001b[39m.\u001b[39mstep \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:539\u001b[0m, in \u001b[0;36mModel._train_step\u001b[1;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m backend_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[39m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(inputs, targets)\n\u001b[0;32m    540\u001b[0m \u001b[39melif\u001b[39;00m backend_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjax\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    541\u001b[0m     \u001b[39m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(\n\u001b[0;32m    543\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_state, inputs, targets\n\u001b[0;32m    544\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:341\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m    338\u001b[0m     total_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss\n\u001b[1;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\optim\\adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:335\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m():\n\u001b[1;32m--> 335\u001b[0m     losses \u001b[39m=\u001b[39m outputs_losses_train(inputs, targets)[\u001b[39m1\u001b[39m]\n\u001b[0;32m    336\u001b[0m     total_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(losses)\n\u001b[0;32m    337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:303\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.outputs_losses_train\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moutputs_losses_train\u001b[39m(inputs, targets):\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs_losses(\u001b[39mTrue\u001b[39;49;00m, inputs, targets, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mlosses_train)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:291\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.outputs_losses\u001b[1;34m(training, inputs, targets, losses_fn)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39mif\u001b[39;00m targets \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(targets)\n\u001b[1;32m--> 291\u001b[0m losses \u001b[39m=\u001b[39m losses_fn(targets, outputs_, loss_fn, inputs, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    292\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(losses, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    293\u001b[0m     losses \u001b[39m=\u001b[39m [losses]\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\data\\data.py:13\u001b[0m, in \u001b[0;36mData.losses_train\u001b[1;34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlosses_train\u001b[39m(\u001b[39mself\u001b[39m, targets, outputs, loss_fn, inputs, model, aux\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a list of losses for training dataset, i.e., constraints.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses(targets, outputs, loss_fn, inputs, model, aux\u001b[39m=\u001b[39;49maux)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\data\\pde.py:127\u001b[0m, in \u001b[0;36mPDE.losses\u001b[1;34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m get_num_args(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 127\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpde(inputs, outputs_pde)\n\u001b[0;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m get_num_args(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m    129\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauxiliary_var_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m, in \u001b[0;36msystem\u001b[1;34m(t, u)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m dim \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m( N_DEGREES_OF_FREEDOM ):\n\u001b[0;32m     31\u001b[0m     y_t [:, dim] \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mjacobian( u, t, i\u001b[39m=\u001b[39mdim, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m )\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m---> 32\u001b[0m     y_tt[:, dim] \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mhessian ( u, t, component\u001b[39m=\u001b[39;49mdim )\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     34\u001b[0m K \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs( torch\u001b[39m.\u001b[39mmatmul( E, K_basis ) )\n\u001b[0;32m     35\u001b[0m C \u001b[39m=\u001b[39m a0 \u001b[39m*\u001b[39m M \u001b[39m+\u001b[39m a1 \u001b[39m*\u001b[39m K\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\gradients.py:283\u001b[0m, in \u001b[0;36mhessian\u001b[1;34m(ys, xs, component, i, j, grad_y)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhessian\u001b[39m(ys, xs, component\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, grad_y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Hessian matrix H: H[i][j] = d^2y / dx_i dx_j, where i,j=0,...,dim_x-1.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[39m    Use this function to compute second-order derivatives instead of ``tf.gradients()``\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39m        H[`i`][`j`].\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     \u001b[39mreturn\u001b[39;00m hessian\u001b[39m.\u001b[39;49m_Hessians(ys, xs, component\u001b[39m=\u001b[39;49mcomponent, i\u001b[39m=\u001b[39;49mi, j\u001b[39m=\u001b[39;49mj, grad_y\u001b[39m=\u001b[39;49mgrad_y)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\gradients.py:251\u001b[0m, in \u001b[0;36mHessians.__call__\u001b[1;34m(self, y, xs, component, i, j, grad_y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mHs:\n\u001b[0;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mHs[key] \u001b[39m=\u001b[39m Hessian(y, xs, component\u001b[39m=\u001b[39mcomponent, grad_y\u001b[39m=\u001b[39mgrad_y)\n\u001b[1;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mHs[key](i, j)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\gradients.py:228\u001b[0m, in \u001b[0;36mHessian.__call__\u001b[1;34m(self, i, j)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    227\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns H[`i`][`j`].\"\"\"\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH(i, j)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\gradients.py:50\u001b[0m, in \u001b[0;36mJacobian.__call__\u001b[1;34m(self, i, j)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39melif\u001b[39;00m backend_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     48\u001b[0m     \u001b[39m# TODO: retain_graph=True has memory leak?\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mys[:, i : i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_y \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mys\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ[i] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(\n\u001b[0;32m     51\u001b[0m         y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxs, grad_outputs\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mones_like(y), create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[39melif\u001b[39;00m backend_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpaddle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     54\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mys[:, i : i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_y \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mys\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Set up DeepXDE model\n",
    "print(\"Setting up DeepXDE model...\")\n",
    "# Define domain\n",
    "geometry = dde.geometry.TimeDomain( t[0], t[-1] )\n",
    "\n",
    "# Define forcing function\n",
    "def pt_force(t):\n",
    "    return torch.cat(\n",
    "        [\n",
    "            (torch.exp(-(t-np.pi)**2) * torch.sin(2*np.pi*t)).view(1, -1) if dim == force_index else (t * 0).reshape(1, -1)\n",
    "            for dim in range(N_DEGREES_OF_FREEDOM)\n",
    "        ],\n",
    "        axis = 0\n",
    "    )\n",
    "\n",
    "# Define parameters\n",
    "E        = dde.Variable( np.ones_like( e ), dtype=torch.float32 )\n",
    "alpha_pi = dde.Variable(1.0)\n",
    "\n",
    "# Define other tensors\n",
    "M = torch.Tensor(m)\n",
    "K_basis = torch.Tensor(k_basis)\n",
    "\n",
    "# Define the ODE residual\n",
    "def system (t, u):\n",
    "    y    = u\n",
    "    y_t  = torch.zeros_like( y ).to(device)\n",
    "    y_tt = torch.zeros_like( y ).to(device)\n",
    "    \n",
    "    for dim in range( N_DEGREES_OF_FREEDOM ):\n",
    "        y_t [:, dim] = dde.grad.jacobian( u, t, i=dim, j=0 ).squeeze()\n",
    "        y_tt[:, dim] = dde.grad.hessian ( u, t, component=dim ).squeeze()\n",
    "    \n",
    "    K = torch.abs( torch.matmul( E, K_basis ) )\n",
    "    C = a0 * M + a1 * K\n",
    "            \n",
    "    residual = (\n",
    "        torch.mm( M, y_tt.permute((1, 0)) )\n",
    "        +\n",
    "        torch.mm( torch.abs(C), y_t.permute((1, 0)) )\n",
    "        +\n",
    "        torch.mm( torch.abs(K), y.permute((1, 0)) )\n",
    "        -\n",
    "        pt_force(t)\n",
    "    ).permute((1, 0))\n",
    "    return alpha_pi * residual\n",
    "\n",
    "bcs = [\n",
    "    dde.icbc.boundary_conditions.PointSetBC( tdata.reshape(-1, 1), udata[:, dim].reshape(-1, 1), component=dim )\n",
    "    for dim in sensor_indices\n",
    "]\n",
    "\n",
    "data = dde.data.PDE(\n",
    "    geometry     = geometry,\n",
    "    pde          = system,\n",
    "    bcs          = bcs,\n",
    "    num_domain   = 10000,\n",
    "    num_boundary = 2,\n",
    "    num_test     = 5\n",
    ")\n",
    "\n",
    "net = dde.nn.FNN(\n",
    "    layer_sizes        = [1] + 20*[32] + [N_DEGREES_OF_FREEDOM],\n",
    "    activation         = \"tanh\",\n",
    "    kernel_initializer = \"Glorot uniform\"\n",
    ")\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=1e-4, external_trainable_variables=[E, alpha_pi])\n",
    "\n",
    "variable = dde.callbacks.VariableValue(\n",
    "  list(E) + [alpha_pi], period=1000, filename=\"variables.dat\"\n",
    ")\n",
    "\n",
    "checkpoint = dde.callbacks.ModelCheckpoint(\"model_files/checkpoints/model\", period=10_000)\n",
    "\n",
    "epoch = 0\n",
    "def plot():\n",
    "    global epoch\n",
    "    epoch += 1\n",
    "    if checkpoint.epochs_since_last_save + 1 < checkpoint.period: return\n",
    "    upred = model.predict(t.reshape(-1, 1))\n",
    "    _, ax = plt.subplots(N_DEGREES_OF_FREEDOM, 1, sharex=True)\n",
    "    plt.suptitle(f\"Epoch {epoch}\")\n",
    "    for dim in range(N_DEGREES_OF_FREEDOM):\n",
    "        ax[dim].plot(t, u[:, dim], label=\"Solution\", color='blue')\n",
    "        if dim in sensor_indices:\n",
    "            ax[dim].plot(tdata, udata[:, dim], label=\"Data\", linestyle=\"None\", marker=\".\", color='orange')\n",
    "        ax[dim].plot(t, upred[:, dim], label=\"Prediction\", color='green')\n",
    "        ax[dim].set_xlabel(r\"$t$\")\n",
    "        ax[dim].set_ylabel(r\"$u_{}(t)$\".format(dim + 1))\n",
    "        if dim == 0:\n",
    "            ax[dim].legend(loc=\"upper right\", ncol=2)\n",
    "    plt.savefig(f\"plots/training/epoch_{epoch}_prediction.png\")\n",
    "    plt.close()\n",
    "\n",
    "checkpoint.on_epoch_begin = plot\n",
    "print(\"Done.\")\n",
    "losshistory, train_state = model.train(iterations=2_000_000, callbacks=[variable, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving model...\")\n",
    "model.save(\"model_files/model\")\n",
    "dde.utils.saveplot(losshistory, train_state, issave=True, isplot=True)\n",
    "print(\"Done.\")\n",
    "\n",
    "#### Print final E vector #####\n",
    "print(\"Final learned E vector\\n\", \"----------\")\n",
    "print(\"E = \\n\", E.detach())\n",
    "\n",
    "print(\"True E vector\\n\", \"----------\")\n",
    "print(\"EK = \\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

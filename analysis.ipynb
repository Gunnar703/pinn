{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from plotter_callback import PlotterCallback\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from generate_data import get_data\n",
    "from msfnn import MsFNN\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "checkpoint_interval = 10_000\n",
    "\n",
    "# Create the argument parser\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# # Add the command line argument\n",
    "# parser.add_argument(\n",
    "#     \"--checkpoint-interval\", type=int, help=\"Interval for saving plots/checkpoints.\"\n",
    "# )\n",
    "\n",
    "# # Parse the arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # Access the value of the command line argument\n",
    "# checkpoint_interval = args.checkpoint_interval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "### Non-dimensionalization\n",
    "ODE is non-dimensionalized as follows.\n",
    "Let\n",
    "$$u = u_cu^*$$\n",
    "$$t = t_ct^*$$\n",
    "$$E = E_cE^*$$\n",
    "Therefore,\n",
    "$$\\frac{du}{dt} = \\frac{u_c}{t}\\frac{du^*}{dt^*}$$\n",
    "$$\\frac{d^2u}{dt^2} = \\frac{u_c}{t^2}\\frac{d^2u^*}{dt^{*2}}$$\n",
    "$$\\frac{u_c}{t^2} [M] \\frac{d^2u^*}{dt^{*2}} + \\frac{u_c}{t} [C] \\frac{du^*}{dt^*} + u_c[K]u^* = F\\left(t_ct^*\\right)$$\n",
    "$$\\iff$$\n",
    "$$\\frac{u_c}{t^2} [M] \\frac{d^2u^*}{dt^{*2}} + \\frac{u_c}{t} \\left( a_0[M] + a_1E_cE^*[K_b] \\right) \\frac{du^*}{dt^*} + u_cE_cE^*[K_b]u^* = F\\left(t_ct^*\\right)$$\n",
    "Further let\n",
    "$$u_c\\equiv \\max{u}$$\n",
    "$$t_c\\equiv \\max{t}$$\n",
    "$$E_c\\equiv \\max{\\mathbb{E}}$$\n",
    "where $\\mathbb{E}$ is the space of all reasonable values of $E$. (chosen here to be $10^8$).\n",
    "Now all network inputs, outputs, and ODE parameters are on the interval $[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"data\"\n",
    "if not os.path.exists(fn):\n",
    "    get_data()\n",
    "dirs = os.listdir(fn)\n",
    "data = {\n",
    "    name.split(\".\")[0]: np.loadtxt(os.path.join(fn, name), max_rows=290)\n",
    "    for name in dirs\n",
    "}\n",
    "\n",
    "# Use FDM to get accelerations\n",
    "acc_3 = (data[\"Vel_3_2D\"][1:] - data[\"Vel_3_2D\"][:-1]) / (\n",
    "    data[\"t\"][1:] - data[\"t\"][:-1]\n",
    ")\n",
    "acc_4 = (data[\"Vel_4_2D\"][1:] - data[\"Vel_4_2D\"][:-1]) / (\n",
    "    data[\"t\"][1:] - data[\"t\"][:-1]\n",
    ")\n",
    "\n",
    "data[\"Acc_3_2D\"] = np.zeros_like(data[\"t\"])\n",
    "data[\"Acc_4_2D\"] = np.zeros_like(data[\"t\"])\n",
    "\n",
    "data[\"Acc_3_2D\"][1:] = acc_3\n",
    "data[\"Acc_4_2D\"][1:] = acc_4\n",
    "\n",
    "# Normalize Data\n",
    "T_MAX = data[\"t\"].max()\n",
    "U_MAX = max(data[\"Disp_3_2D\"].max(), data[\"Disp_4_2D\"].max())\n",
    "\n",
    "data[\"t\"] /= T_MAX\n",
    "for name in data:\n",
    "    if \"Disp\" in name:\n",
    "        data[name] /= U_MAX\n",
    "    elif \"Vel\" in name:\n",
    "        data[name] *= T_MAX / U_MAX\n",
    "\n",
    "# For convenience\n",
    "a0, a1 = data[\"Damp_param\"]\n",
    "\n",
    "# Get Constant Tensors ready\n",
    "M = torch.Tensor(data[\"M\"])\n",
    "Kb = torch.Tensor(data[\"k_basis\"])\n",
    "\n",
    "\n",
    "# Define interpolation of F. Returns M x N_DIM tensor.\n",
    "def load(t: torch.Tensor):\n",
    "    x = t * T_MAX\n",
    "    xp = data[\"t\"] * T_MAX\n",
    "    fp = data[\"load\"]\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        x = x.detach().cpu().numpy().squeeze()\n",
    "        f = np.interp(x, xp, fp)\n",
    "        f = torch.Tensor(f)\n",
    "        ret = torch.zeros(t.shape[0], 4)\n",
    "        ret[:, 3] = f\n",
    "        ret = ret.permute((1, 0))\n",
    "    else:\n",
    "        f = np.interp(x, xp, fp).squeeze()\n",
    "        ret = np.zeros((t.shape[0], 4))\n",
    "        ret[:, 3] = f\n",
    "        ret = ret.T\n",
    "    return ret * 1e3  # convert kN -> N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry - just an interval\n",
    "geom = dde.geometry.TimeDomain(data[\"t\"].min(), data[\"t\"].max())\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def get_u_derivatives(t: torch.Tensor, u: torch.Tensor) -> tuple[torch.Tensor, ...]:\n",
    "    u_t, u_tt = [u * 0] * 2\n",
    "    for dim in range(int(u.shape[1])):\n",
    "        u_t[:, dim] = dde.grad.jacobian(u, t, i=dim).squeeze()\n",
    "        u_tt[:, dim] = dde.grad.hessian(u, t, component=dim).squeeze()\n",
    "    return u_t, u_tt\n",
    "\n",
    "\n",
    "# Learnable parameter/s\n",
    "E = dde.Variable(0.6)\n",
    "\n",
    "\n",
    "# ODE definition\n",
    "def ode_sys(t, u):\n",
    "    F = load(t)\n",
    "    K = Kb * E**2 * 1e8\n",
    "    C = a0 * M + a1 * K\n",
    "\n",
    "    y_t, y_tt = get_u_derivatives(t, u)\n",
    "    y = u.permute((1, 0))\n",
    "    y_t = y_t.permute((1, 0))\n",
    "    y_tt = y_tt.permute((1, 0))\n",
    "\n",
    "    # Whatever E is learned to be, it is actually 1e8 times that value\n",
    "    U = y * U_MAX\n",
    "    DU_DT = y_t * U_MAX / T_MAX\n",
    "    D2U_DT2 = y_tt * U_MAX / T_MAX**2\n",
    "\n",
    "    mass_term = M @ D2U_DT2\n",
    "    damp_term = C @ DU_DT\n",
    "    stiff_term = K @ U\n",
    "    force_term = F\n",
    "    residual = mass_term + damp_term + stiff_term - force_term\n",
    "    residual = residual.permute((1, 0))\n",
    "    return residual / 1e8\n",
    "\n",
    "\n",
    "# Boundary conditions definition\n",
    "def differentiate_output(t, u, component, order):\n",
    "    if order == 1:\n",
    "        return dde.grad.jacobian(u, t, i=component)\n",
    "    return dde.grad.hessian(u, t, component=component)\n",
    "\n",
    "\n",
    "t_data = data[\"t\"].reshape(-1, 1)\n",
    "zero_vector = np.array([[0]])\n",
    "\n",
    "# IC for unknown dimensions\n",
    "v0 = [\n",
    "    dde.icbc.PointSetOperatorBC(\n",
    "        zero_vector, zero_vector, lambda t, u, X: differentiate_output(t, u, i, 1)\n",
    "    )\n",
    "    for i in (0, 1)\n",
    "]\n",
    "\n",
    "# Known dimensions\n",
    "vi = [\n",
    "    dde.icbc.PointSetOperatorBC(\n",
    "        t_data,\n",
    "        data[\"Vel_3_2D\"].reshape(-1, 1),\n",
    "        lambda t, u, X: differentiate_output(t, u, 1, 1),\n",
    "    ),\n",
    "    dde.icbc.PointSetOperatorBC(\n",
    "        t_data,\n",
    "        data[\"Vel_4_2D\"].reshape(-1, 1),\n",
    "        lambda t, u, X: differentiate_output(t, u, 3, 1),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Position BC\n",
    "xi = [\n",
    "    dde.icbc.PointSetBC(t_data, data[\"Disp_3_2D\"].reshape(-1, 1), component=1),\n",
    "    dde.icbc.PointSetBC(t_data, data[\"Disp_4_2D\"].reshape(-1, 1), component=3),\n",
    "]\n",
    "\n",
    "pde = dde.data.PDE(\n",
    "    geom,\n",
    "    ode_sys,\n",
    "    xi,\n",
    "    num_domain=1000,\n",
    "    num_boundary=2,\n",
    "    anchors=data[\"t\"].reshape(-1, 1),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure directories exist and are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folders:\n",
      "Checking model_files/checkpoints...\n",
      "Checking plots/training...\n"
     ]
    }
   ],
   "source": [
    "necessary_directories = [[\"model_files\", \"checkpoints\"], [\"plots\", \"training\"]]\n",
    "folders_created = []\n",
    "for dir in necessary_directories:\n",
    "    if not os.path.isdir(dir[0]):\n",
    "        os.mkdir(dir[0])\n",
    "        folders_created.append(dir[0])\n",
    "    if not os.path.isdir(f\"{dir[0]}/{dir[1]}\"):\n",
    "        os.mkdir(f\"{dir[0]}/{dir[1]}\")\n",
    "        folders_created.append(f\"{dir[0]}/{dir[1]}\")\n",
    "print(\"Created folders:\" + \"\\n> \".join([\"\", *folders_created]))\n",
    "\n",
    "## Ensure output files (model_files/checkpoints, plots/training) are empty.\n",
    "for path in [\"/\".join(entry) for entry in necessary_directories]:\n",
    "    print(f\"Checking {path}...\")\n",
    "    files = os.listdir(path)\n",
    "    if not files:\n",
    "        continue\n",
    "    print(f\"{path} not empty. Deleting contents...\")\n",
    "    for file in files:\n",
    "        filepath = os.path.join(path, file)\n",
    "        try:\n",
    "            os.unlink(filepath)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to delete %s. Reason: %s\" % (filepath, e))\n",
    "\n",
    "if not os.path.exists(\"out_files\"):\n",
    "    os.mkdir(\"out_files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "variable = dde.callbacks.VariableValue(var_list=[E], period=checkpoint_interval, filename=\"out_files/variables.dat\")\n",
    "\n",
    "plotter_callback = PlotterCallback(\n",
    "    period=checkpoint_interval, \n",
    "    filepath=\"plots/training\", \n",
    "    data=data,\n",
    "    E=E, \n",
    "    t_max=T_MAX, \n",
    "    u_max=U_MAX, \n",
    "    plot_residual=False\n",
    ")\n",
    "\n",
    "resampler = dde.callbacks.PDEPointResampler(period=1_000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Compile, and Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000197 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                                            Test loss                                             Test metric\n",
      "0         [4.23e-06, 1.21e+02, 3.69e+02, 7.57e-02, 1.50e-01]    [4.23e-06, 1.21e+02, 3.69e+02, 7.57e-02, 1.50e-01]    []  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[39m=\u001b[39m dde\u001b[39m.\u001b[39mModel(pde, net)\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m, external_trainable_variables\u001b[39m=\u001b[39mE)\n\u001b[1;32m---> 10\u001b[0m losshistory, train_state \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m     11\u001b[0m     iterations\u001b[39m=\u001b[39;49m\u001b[39m50_000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[variable, plotter_callback, resampler]\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL-BFGS\u001b[39m\u001b[39m\"\u001b[39m, external_trainable_variables\u001b[39m=\u001b[39mE)\n\u001b[0;32m     15\u001b[0m model\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     23\u001b[0m     te \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m took \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m s\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, te \u001b[39m-\u001b[39m ts))\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:624\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[39mif\u001b[39;00m iterations \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo iterations for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_name))\n\u001b[1;32m--> 624\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_sgd(iterations, display_every)\n\u001b[0;32m    625\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mon_train_end()\n\u001b[0;32m    627\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:641\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[1;34m(self, iterations, display_every)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mon_batch_begin()\n\u001b[0;32m    638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_state\u001b[39m.\u001b[39mset_data_train(\n\u001b[0;32m    639\u001b[0m     \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtrain_next_batch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[0;32m    640\u001b[0m )\n\u001b[1;32m--> 641\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step(\n\u001b[0;32m    642\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_state\u001b[39m.\u001b[39;49mX_train,\n\u001b[0;32m    643\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_state\u001b[39m.\u001b[39;49my_train,\n\u001b[0;32m    644\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_state\u001b[39m.\u001b[39;49mtrain_aux_vars,\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    647\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_state\u001b[39m.\u001b[39mepoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_state\u001b[39m.\u001b[39mstep \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:539\u001b[0m, in \u001b[0;36mModel._train_step\u001b[1;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m backend_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[39m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(inputs, targets)\n\u001b[0;32m    540\u001b[0m \u001b[39melif\u001b[39;00m backend_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjax\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    541\u001b[0m     \u001b[39m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(\n\u001b[0;32m    543\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_state, inputs, targets\n\u001b[0;32m    544\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:341\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m    338\u001b[0m     total_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss\n\u001b[1;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\optim\\adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\deepxde\\model.py:338\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    336\u001b[0m total_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(losses)\n\u001b[0;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 338\u001b[0m total_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    339\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aglor\\anaconda3\\envs\\pinn\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = MsFNN(\n",
    "    layer_sizes=[1] + 5*[100] + [4],\n",
    "    activation=\"tanh\",\n",
    "    kernel_initializer=\"Glorot uniform\",\n",
    "    sigmas=[1, 10, 50]\n",
    ")\n",
    "\n",
    "model = dde.Model(pde, net)\n",
    "model.compile(optimizer=\"adam\", lr=5e-5, external_trainable_variables=E)\n",
    "losshistory, train_state = model.train(\n",
    "    iterations=50_000, callbacks=[variable, plotter_callback, resampler]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"L-BFGS\", external_trainable_variables=E)\n",
    "model.train()\n",
    "\n",
    "dde.utils.external.save_best_state(train_state, \"out_files/best_training_loss.dat\", \"out_files/best_test_loss.dat\")\n",
    "\n",
    "dde.saveplot(\n",
    "    losshistory,\n",
    "    train_state,\n",
    "    loss_fname=\"out_files/loss.dat\",\n",
    "    train_fname=\"out_files/train.dat\",\n",
    "    test_fname=\"out_files/test.dat\",\n",
    ")\n",
    "model.save(\"model_files/msfnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
